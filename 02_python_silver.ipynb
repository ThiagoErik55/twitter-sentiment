{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b11e969",
   "metadata": {},
   "source": [
    "Configuração e leitura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b6d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c295c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados originais (Bronze): 1600000 linhas\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/bronze/dados_brutos.csv')\n",
    "print(f\"Dados originais (Bronze): {df.shape[0]} linhas\")\n",
    "\n",
    "TEXT_COL = 'Texto_Bruto' \n",
    "SENTIMENT_COL = 'Sentimento_Bruto'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a03a4ce",
   "metadata": {},
   "source": [
    "Transformação 1: Limpeza Estrutural e Tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2b73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar colunas relevantes e renomear para nomes limpos\n",
    "df_clean = df[['Sentimento_Bruto', 'Data_Bruta', 'Texto_Bruto']].copy()\n",
    "df_clean.columns = ['sentimento_label', 'data_postagem', 'texto_original']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c82d39b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thiago Erik\\AppData\\Local\\Temp\\ipykernel_36972\\2212057632.py:1: FutureWarning: Parsed string \"Mon Apr 06 22:19:45 PDT 2009\" included an un-recognized timezone \"PDT\". Dropping unrecognized timezones is deprecated; in a future version this will raise. Instead pass the string without the timezone, then use .tz_localize to convert to a recognized timezone.\n",
      "  df_clean['data_postagem'] = pd.to_datetime(df_clean['data_postagem'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linhas após limpeza estrutural: 1599603. Duplicatas/Nulos removidos: 397\n"
     ]
    }
   ],
   "source": [
    "df_clean['data_postagem'] = pd.to_datetime(df_clean['data_postagem'], errors='coerce')\n",
    "df_clean['sentimento_binario'] = df_clean['sentimento_label'].apply(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "# C. Remoção de Duplicatas e Nulos\n",
    "linhas_antes = len(df_clean)\n",
    "df_clean.drop_duplicates(inplace=True)\n",
    "df_clean.dropna(inplace=True) \n",
    "linhas_depois = len(df_clean)\n",
    "\n",
    "print(f\"\\nLinhas após limpeza estrutural: {linhas_depois}. Duplicatas/Nulos removidos: {linhas_antes - linhas_depois}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c230475",
   "metadata": {},
   "source": [
    "Transformação 2: Processamento de Linguagem Natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e23b9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto Original vs. Texto Limpo:\n",
      "                                      texto_original  \\\n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
      "1  is upset that he can't update his Facebook by ...   \n",
      "2  @Kenichan I dived many times for the ball. Man...   \n",
      "3    my whole body feels itchy and like its on fire    \n",
      "4  @nationwideclass no, it's not behaving at all....   \n",
      "\n",
      "                                         texto_limpo  \n",
      "0  awww thats a bummer  you shoulda got david car...  \n",
      "1  is upset that he cant update his facebook by t...  \n",
      "2  i dived many times for the ball managed to sav...  \n",
      "3     my whole body feels itchy and like its on fire  \n",
      "4  no its not behaving at all im mad why am i her...  \n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    \n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    \n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "df_clean['texto_limpo'] = df_clean['texto_original'].apply(clean_text)\n",
    "\n",
    "print(\"\\nTexto Original vs. Texto Limpo:\")\n",
    "print(df_clean[['texto_original', 'texto_limpo']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70f6f09",
   "metadata": {},
   "source": [
    "Transformação 3: Análise de Sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b3cba54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métrica de Sentimento Gerada:\n",
      "                                         texto_limpo  score_sentimento\n",
      "0  awww thats a bummer  you shoulda got david car...             0.200\n",
      "1  is upset that he cant update his facebook by t...             0.000\n",
      "2  i dived many times for the ball managed to sav...             0.500\n",
      "3     my whole body feels itchy and like its on fire             0.200\n",
      "4  no its not behaving at all im mad why am i her...            -0.625\n"
     ]
    }
   ],
   "source": [
    "# O score vai de -1 (muito negativo) a +1 (muito positivo)\n",
    "def get_textblob_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Criar a coluna métrica principal (Polaridade)\n",
    "df_clean['score_sentimento'] = df_clean['texto_limpo'].apply(get_textblob_sentiment)\n",
    "\n",
    "print(\"\\nMétrica de Sentimento Gerada:\")\n",
    "print(df_clean[['texto_limpo', 'score_sentimento']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594da9ad",
   "metadata": {},
   "source": [
    "Finalização e Carga na Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ab299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dados Silver salvos com sucesso: 1599603 linhas\n"
     ]
    }
   ],
   "source": [
    "# Adicionar metadado de processamento\n",
    "df_clean['data_processamento'] = datetime.now()\n",
    "\n",
    "# Salvar na camada Silver\n",
    "output_path = 'data/silver/dados_limpos.csv'\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nDados Silver salvos com sucesso: {df_clean.shape[0]} linhas\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
