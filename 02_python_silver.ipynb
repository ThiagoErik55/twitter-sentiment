{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b11e969",
   "metadata": {},
   "source": [
    "Configuração e leitura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b6d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c295c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados originais (Bronze): 1600000 linhas\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/bronze/dados_brutos.csv')\n",
    "print(f\"Dados originais (Bronze): {df.shape[0]} linhas\")\n",
    "\n",
    "TEXT_COL = 'Texto_Bruto' \n",
    "SENTIMENT_COL = 'Sentimento_Bruto'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a03a4ce",
   "metadata": {},
   "source": [
    "Transformação 1: Limpeza Estrutural e Tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2b73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar colunas relevantes e renomear para nomes limpos\n",
    "df_clean = df[['Sentimento_Bruto', 'Data_Bruta', 'Texto_Bruto']].copy()\n",
    "df_clean.columns = ['sentimento_label', 'data_postagem', 'texto_original']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c82d39b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linhas após limpeza estrutural: 1600000. Duplicatas/Nulos removidos: 0\n"
     ]
    }
   ],
   "source": [
    "df_clean['data_postagem'] = pd.to_datetime(df_clean['data_postagem'], errors='coerce')\n",
    "df_clean['sentimento_binario'] = df_clean['sentimento_label'].apply(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "# C. Remoção de Duplicatas e Nulos\n",
    "linhas_antes = len(df_clean)\n",
    "df_clean.drop_duplicates(inplace=True)\n",
    "df_clean.dropna(inplace=True) \n",
    "linhas_depois = len(df_clean)\n",
    "\n",
    "print(f\"\\nLinhas após limpeza estrutural: {linhas_depois}. Duplicatas/Nulos removidos: {linhas_antes - linhas_depois}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c230475",
   "metadata": {},
   "source": [
    "Transformação 2: Processamento de Linguagem Natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e23b9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto Original vs. Texto Limpo:\n",
      "                 texto_original                 texto_limpo\n",
      "0  Mon Apr 06 22:19:45 PDT 2009  mon apr 06 221945 pdt 2009\n",
      "1  Mon Apr 06 22:19:49 PDT 2009  mon apr 06 221949 pdt 2009\n",
      "2  Mon Apr 06 22:19:53 PDT 2009  mon apr 06 221953 pdt 2009\n",
      "3  Mon Apr 06 22:19:57 PDT 2009  mon apr 06 221957 pdt 2009\n",
      "4  Mon Apr 06 22:19:57 PDT 2009  mon apr 06 221957 pdt 2009\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    \n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    \n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "df_clean['texto_limpo'] = df_clean['texto_original'].apply(clean_text)\n",
    "\n",
    "print(\"\\nTexto Original vs. Texto Limpo:\")\n",
    "print(df_clean[['texto_original', 'texto_limpo']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70f6f09",
   "metadata": {},
   "source": [
    "Transformação 3: Análise de Sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b3cba54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métrica de Sentimento Gerada:\n",
      "                  texto_limpo  score_sentimento\n",
      "0  mon apr 06 221945 pdt 2009               0.0\n",
      "1  mon apr 06 221949 pdt 2009               0.0\n",
      "2  mon apr 06 221953 pdt 2009               0.0\n",
      "3  mon apr 06 221957 pdt 2009               0.0\n",
      "4  mon apr 06 221957 pdt 2009               0.0\n"
     ]
    }
   ],
   "source": [
    "# O score vai de -1 (muito negativo) a +1 (muito positivo)\n",
    "def get_textblob_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Criar a coluna métrica principal (Polaridade)\n",
    "df_clean['score_sentimento'] = df_clean['texto_limpo'].apply(get_textblob_sentiment)\n",
    "\n",
    "print(\"\\nMétrica de Sentimento Gerada:\")\n",
    "print(df_clean[['texto_limpo', 'score_sentimento']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594da9ad",
   "metadata": {},
   "source": [
    "Finalização e Carga na Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ab299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dados Silver salvos com sucesso: 1600000 linhas\n"
     ]
    }
   ],
   "source": [
    "# Adicionar metadado de processamento\n",
    "df_clean['data_processamento'] = datetime.now()\n",
    "\n",
    "# Salvar na camada Silver\n",
    "output_path = 'data/silver/dados_limpos.csv'\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nDados Silver salvos com sucesso: {df_clean.shape[0]} linhas\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
